# -*- coding: utf-8 -*-
"""Projet_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tgIdsMvOv4KONow4BqSgGfzPIKrBcwbd
"""

import pandas as pd
import numpy as np
import re

df = pd.read_csv("rappelconso1.csv",sep=";")

df.shape

df_new=df.copy()

"""**SUPPRIMER LES COLONNES INUTILES** **REMOVE UNNECESSARY COLUMNS**


1.   Élément de liste
2.   Élément de liste


"""

# Supprimer les colonnes inutiles

df_new = df_new.drop(['ndeg_de_version','liens_vers_les_images','lien_vers_la_liste_des_distributeurs','lien_vers_la_liste_des_produits','lien_vers_affichette_pdf','lien_vers_la_fiche_rappel','rappelguid','numero_de_contact','marque_de_salubrite','informations_complementaires_publiques','description_complementaire_du_risque'],axis=1)

"""**REMPLACER LES NaN par la chaîne 'Non renseigné'** **REPLACE NaN with string 'Not specified'**"""

# Remplacer les NaN par la chaîne 'Non renseigne'
df_new.iloc[:, :-2] = df_new.iloc[:, :-2].replace(np.nan,"non renseigné")
df_new.head()

df_new.shape

"""**SUPPRIMER LES JOURS ET REMPLACER LES MOIS + TYPES DATETIME** **DELETE DAYS AND REPLACE MONTHS + DATETIME TYPES**"""

df_procedure_de_rappel = df_new.copy()

### Remplacer les bonnes dates

#df_new['date_de_fin_de_la_procedure_de_rappel'] = df_new['date_de_fin_de_la_procedure_de_rappel'].str.replace('d√©cembre', 'décembre')
#df_new['date_de_fin_de_la_procedure_de_rappel'] = df_new['date_de_fin_de_la_procedure_de_rappel'].str.replace('ao√ªt', 'aout')

# Supprimer les lundis, mardis, mercredis etc #Delete Mondays, Tuesdays, Wednesdays

df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'] = df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'].str.replace(r'\b(lundi|mardi|mercredi|jeudi|vendredi|samedi|dimanche)\b', '', regex=True)

# convertir les mois en numeros #convert months to numbers

mois= {
    'janvier': '01',
    'février': '02',
    'mars': '03',
    'avril': '04',
    'mai': '05',
    'juin': '06',
    'juillet': '07',
    'août': '08',
    'septembre': '09',
    'octobre': '10',
    'novembre': '11',
    'décembre': '12'
}

df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'] = df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'].replace(mois, regex=True)

#convertir la colonne en date #convert the column to date

df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'] = pd.to_datetime(df_procedure_de_rappel['date_de_fin_de_la_procedure_de_rappel'])
df_procedure_de_rappel["date_de_publication"] = pd.to_datetime(df_procedure_de_rappel['date_de_publication'])

df_procedure_de_rappel.iloc[304:315]

df_procedure_de_rappel.info()

"""**SERAPATION DE LA COLONNE "date_debut_fin_de_commercialisation"**"""

ddfc=df_procedure_de_rappel

# Séparer la colonne en 2 entre les dates

ddfc[['date_debut_commercialisation','date_fin_commercialisation']] = ddfc['date_debut_fin_de_commercialisation'].str.split(' au ', expand=True)

# Condition Selectionner les colonnes qui contient jusqu'

condition = (ddfc['date_debut_commercialisation'].str.contains('Jusq') == True)
ddfc[condition].shape

# Copier-coller la condition "jusqu'au" dans la colonne date_fin_commercialisation et insérer la valeur Nan dans date_debut_commercialisation

ddfc.loc[ddfc[condition].index, 'date_fin_commercialisation'] = ddfc.loc[ddfc[condition].index, 'date_debut_commercialisation']
ddfc.loc[ddfc[condition].index, 'date_debut_commercialisation'] = np.NaN
ddfc[condition][['date_debut_commercialisation', 'date_fin_commercialisation']]

# Extraire la date du format "jour/mois/année"

ddfc['date_debut_commercialisation'] = ddfc['date_debut_commercialisation'].str.extract(r'(\d{2}/\d{2}/\d{4})')

ddfc['date_debut_commercialisation'] = pd.to_datetime(ddfc['date_debut_commercialisation'], format='%d/%m/%Y', errors='coerce')

ddfc['date_fin_commercialisation'] = ddfc['date_fin_commercialisation'].str.extract(r'(\d{2}/\d{2}/\d{4})')

ddfc['date_fin_commercialisation'] = pd.to_datetime(ddfc['date_fin_commercialisation'], format='%d/%m/%Y',errors='coerce')

#convertir la colonne en date

ddfc['date_debut_commercialisation'] = pd.to_datetime(ddfc['date_debut_commercialisation'])
ddfc["date_fin_commercialisation"] = pd.to_datetime(ddfc['date_fin_commercialisation'])

ddfc.drop(columns=['date_debut_fin_de_commercialisation'], inplace=True)

ddfc.iloc [790:800] #[1100:1115] #[35:40]  #[304:315]

ddfc.info()

"""**SUPPRIMER LES DOUBLONS DE LA "reference fiche"**"""

df_reference_fiche = ddfc

# Supprimer les lignes avec des doublons dans la colonne "reference_fiche"

df_reference_fiche = df_reference_fiche.drop_duplicates(subset='reference_fiche', keep='first')

df_reference_fiche.shape

"""**Création de catégorie Motif du rappel**"""

dca = df_reference_fiche

df_separate = dca.copy()

df_separate['type_de_probleme'] = 'Autre'

conditions1 = (dca['motif_du_rappel'].str.contains('listeria', case=False)|
              dca['motif_du_rappel'].str.contains('listéria', case=False) |
              dca['motif_du_rappel'].str.contains('lystéria', case=False) |
              dca['risques_encourus_par_le_consommateur'].str.contains('list', case=False))

df_separate.loc[conditions1, 'type_de_probleme'] = 'Listéria'

conditions2 = (dca['motif_du_rappel'].str.contains('éthyl', case=False) |
               dca['motif_du_rappel'].str.contains('ethyl', case=False) |
               dca['motif_du_rappel'].str.contains('ETO', case=False))

df_separate.loc[conditions2, 'type_de_probleme'] = 'Oxyde d\'éthylène détecté'

conditions3 = (dca['motif_du_rappel'].str.contains('salmonel', case=False))

df_separate.loc[conditions3, 'type_de_probleme'] = 'Salmonelle'

conditions4 = dca['motif_du_rappel'].str.lower().fillna('').str.contains('cereus', case=False)

df_separate.loc[conditions4, 'type_de_probleme'] = 'Bacillus cereus'

conditions5 = (dca['motif_du_rappel'].str.contains('phycot', case=False) |
              dca['motif_du_rappel'].str.contains('ASP', case=True))

df_separate.loc[conditions5, 'type_de_probleme'] = 'Phycotoxine'

conditions6 = (dca['motif_du_rappel'].str.contains('allerg', case=False))

df_separate.loc[conditions6, 'type_de_probleme'] = 'Allergène'

conditions7 = (dca['motif_du_rappel'].str.contains('date limite de consommation', case=False) |
               dca['motif_du_rappel'].str.contains('DLC', case=True))

df_separate.loc[conditions7, 'type_de_probleme'] = 'DLC erronée'

conditions8 = dca['motif_du_rappel'].str.lower().fillna('').str.contains('Lygomme FM 3604', case=False)

df_separate.loc[conditions8, 'type_de_probleme'] = 'Lygomme FM 3604'

conditions9 = (dca['motif_du_rappel'].str.contains('pesti', case=False) |
              dca['motif_du_rappel'].str.contains('Chlorpy', case=False))


df_separate.loc[conditions9, 'type_de_probleme'] = 'Pesticides'

conditions10 = (dca['motif_du_rappel'].str.contains('E.COLI STEC', case=False) |
                dca['motif_du_rappel'].str.contains('E. COLI', case=False) |
                dca['motif_du_rappel'].str.contains('E.COLI', case=False))

df_separate.loc[conditions10, 'type_de_probleme'] = 'Escherichia coli'

conditions11 = (dca['motif_du_rappel'].str.contains('etiquetage', case=False) |
              dca['motif_du_rappel'].str.contains('étiquetage', case=False)|
              dca['motif_du_rappel'].str.contains('étiquet', case=False)|
              dca['motif_du_rappel'].str.contains('etiquet', case=False))

df_separate.loc[conditions11, 'type_de_probleme'] = 'Erreur etiquetage'

conditions12 = dca['motif_du_rappel'].str.lower().fillna('').str.contains('butylphenyl methylpropional', case=False)

df_separate.loc[conditions12, 'type_de_probleme'] = 'Butylphenyl methylpropional'

conditions13 = (dca['motif_du_rappel'].str.contains('electr', case=False)|
                dca['motif_du_rappel'].str.contains('confor', case=False)|
                dca['motif_du_rappel'].str.contains('dange', case=False)|
                dca['motif_du_rappel'].str.contains('isol', case=False)|
                dca['motif_du_rappel'].str.contains('accident', case=False)|
                dca['motif_du_rappel'].str.contains('blessure', case=False)|
                dca['motif_du_rappel'].str.contains('incen', case=False)|
                dca['motif_du_rappel'].str.contains('defect', case=False)|
                dca['motif_du_rappel'].str.contains('défect', case=False)|
                dca['motif_du_rappel'].str.contains('frein', case=False)|
                dca['motif_du_rappel'].str.contains('moteur', case=False)|
                dca['motif_du_rappel'].str.contains('secu', case=False)|
                dca['motif_du_rappel'].str.contains('sécu', case=False))

df_separate.loc[conditions13, 'type_de_probleme'] = 'Piece defectueuse'

df_separate

df_separate = df_separate.drop('motif_du_rappel', axis=1)

df_separate = df_separate.rename(columns={'type_de_probleme': 'motif_du_rappel'})

df_separate.info()

"""**Tri par type de marques** **Sort by brand type**
**marques nationales, marques de destributeurs, marques non renseignée** **national marks, brands of destributeurs, brands not specified**
"""

df_types_de_marques = df_separate.copy()

# MDD

df_types_de_marques['type_de_marque'] = ''

# Liste des mots à vérifier
mots_a_verifier = ['auchan', 'carrefour', 'leader price', 'monoprix', 'casino', 'super u', 'leclerc', 'lidl', 'cora', 'intermarche', 'match',
                  'coccinelle' 'diagonal', 'lidl', 'maximarché', 'aldi', 'système U', 'carrefour extra', 'picard', 'U saveurs', 'metro chef',
                  'franprix', 'netto', 'simpl', 'Prix Mini', 'reflets de France', 'MARQUE U', 'Belle France', 'tOP BUDGET', 'pouce', 'mmm!',
                  'Monique Ranou', 'Pâturages', 'paturages', 'Chabrior', 'Paquito', 'Odyssée', 'odyssee', 'Capitaine Cook', 'Marque Repère',
                  'Nos Régions ont du Talent', 'Nos Regions ont du Talent', 'Tradizioni d\'Italia', 'Origine du goût', 'Volaé', 'Jean Rozé',
                  'Alesto', 'Naturalia', 'Envia', 'Chênes d’argent', 'Saveurs de nos régions', 'Bellarom', 'Solevita', 'L’étal du boucher',
                  'Cien', 'W5', 'Itinéraire des Saveurs', 'Irrésistibles', 'Eco+', 'Veggie Marché', 'Adélie', 'adelie', 'toupargel',
                  'Eskiss', 'smicy', 'trium', 'U bio', 'ITINERAIRE DES SAVEURS', 'intermarché', 'Pâturage', 'tous les jours', 'Mon Marché Plaisir',
                  'MDD', 'Itinéraire de nos Régions', 'Itineraire de nos Regions', 'Pays Gourmand', 'Producteurs & Commerçants', 'Metro Premium',
                  'Ikea', 'bio village']

# Vérifier si l'un des mots est présent dans chaque cellule de 'nom_de_la_marque_du_produit' (sans distinction de cas)
df_types_de_marques.loc[df_types_de_marques['nom_de_la_marque_du_produit'].apply(lambda x: any(mot.lower() in str(x).lower() for mot in mots_a_verifier)), 'type_de_marque'] = 'MDD'

# Marque non renseignée

# Liste des mots à vérifier
mots_a_verifier = ['sans marque', '#name?', 'aucune', '_', 'sans', 'sans (vendue au rayon traditionnel)',
                  'en vrac en rayon traditionnel', 'élaboré dans nos laboratoire', 'marque neutre', 'patisserie', 'EMB 94073Le', 'EMB 94073 Le',
                  'en barquette sous film au rayon libre service ou en vrac au rayon traditionnel', 'no name', 'saucisson sec', 'aucun', 'neutre',
                  'Vente au détail', 'PAVE DE SAUMON', 'Jambon vendu en tranche au rayon traditionnel-charcuterie', 'pas de marque',
                  'PAS DE MARQUE : FABRICATION MAISON', 'Vente au rayon traditionnel', 'FABRICATION MAISON', 'Elaborés sur place',
                  'préparé par le magasin', 'Vendu au rayon traiteur traditionnel', 'PRE EMBALLE', 'MAGASIN', 'fromage frais', 'Non concerné',
                  'en vrac au rayon Traditionnel', 'traiteur', 'Produits vendus au rayon traditionnel', 'Fabriqué sur place', 'Fabriquée sur place',
                  'Sauce Sweet Chili 0 % - 250 ml', 'TARLETTES ELABOREES PAR NOS ATELIERS', 'Têtes de veau roulées',
                  'Jambon vendu en tranche au rayon traditionnel - charcuterie', 'Jambon persillé maison', 'creme crue', 'beurre nature et demi sel',
                  'fromage demi sec', 'faisselle', 'camembert', 'RAYON VRAC' ]

# Vérifier si l'un des mots est présent dans chaque cellule de 'nom_de_la_marque_du_produit' (sans distinction de cas)
df_types_de_marques.loc[df_types_de_marques['nom_de_la_marque_du_produit'].apply(lambda x: any(mot.lower() in str(x).lower() for mot in mots_a_verifier)), 'type_de_marque'] = 'Marque non renseignée'

# "U" traité separement comme MDD

df_types_de_marques['type_de_marque'] = df_types_de_marques.apply(lambda row: 'MDD' if 'U' == str(row['nom_de_la_marque_du_produit']).upper() else row['type_de_marque'], axis=1)

# "/" traité comme marque non renseignée

df_types_de_marques['type_de_marque'] = df_types_de_marques.apply(lambda row: 'Sans marque' if str(row['nom_de_la_marque_du_produit']) == '/' else row['type_de_marque'], axis=1)

# "-" traité comme marque non renseignée

df_types_de_marques['type_de_marque'] = df_types_de_marques.apply(lambda row: 'Sans marque' if str(row['nom_de_la_marque_du_produit']) == '-' else row['type_de_marque'], axis=1)

# "" (vide) traité comme marque non renseignée

df_types_de_marques['type_de_marque'] = df_types_de_marques.apply(lambda row: 'Sans marque' if str(row['nom_de_la_marque_du_produit']) == '' else row['type_de_marque'], axis=1)

# Les champs de la colonne 'type_de_marque' prennent la valeur 'Marques nationales' si elles n'ont pas reçu de valeur

df_types_de_marques['type_de_marque'] = df_types_de_marques['type_de_marque'].replace('','Marques nationales')

df_types_de_marques.head()

df_types_de_marques.info()

"""**Connaître le pays d'origine des produits** **Know the country of origin of the products**

1.   Élément de liste
2.   Élément de liste


"""

df_pays_origine = df_types_de_marques.copy()

# Créer des colonnes vides pour le pays d'origine et le fabricant
df_pays_origine['pays_origine'] = ''

def extract_info(row):
    ean_pattern = re.compile(r'\b(\d{13})\b')
    value = row['identification_des_produits']
    ean = None  # Initialiser ean à None

    if isinstance(value, str):
        match = ean_pattern.search(value)
        if match:
            ean = match.group(1)
            # Extraire d'autres informations si nécessaire
            # ...

    # Utiliser la liste des plages de chiffres pour déterminer le pays d'origine
    if ean:
        pays_code = ean[:3]
        if 0 <= int(pays_code) <= 99:
            row['pays_origine'] = 'USA'
        elif 200 <= int(pays_code) <= 299:
            row['pays_origine'] = 'Non attribué (réservé)'
        elif 300 <= int(pays_code) <= 379:
            row['pays_origine'] = 'France'
        elif 380 == int(pays_code):
            row['pays_origine'] = 'Bulgarie'
        elif 383 == int(pays_code):
            row['pays_origine'] = 'Slovénie'
        elif 385 == int(pays_code):
            row['pays_origine'] = 'Croatie'
        elif 387 == int(pays_code):
            row['pays_origine'] = 'Bosnie-Herzégovine'
        elif 400 <= int(pays_code) <= 440:
            row['pays_origine'] = 'Allemagne'
        elif 450 <= int(pays_code) <= 459 or 490 == int(pays_code):
            row['pays_origine'] = 'Japon'
        elif 469 >= int(pays_code) >= 460:
            row['pays_origine'] = 'Russie'
        elif 470 == int(pays_code):
            row['pays_origine'] = 'Kirghizistan'
        elif 471 == int(pays_code):
            row['pays_origine'] = 'Taïwan'
        elif 474 == int(pays_code):
            row['pays_origine'] = 'Estonie'
        elif 475 == int(pays_code):
            row['pays_origine'] = 'Lettonie'
        elif 476 == int(pays_code):
            row['pays_origine'] = 'Azerbaïdjan'
        elif 477 == int(pays_code):
            row['pays_origine'] = 'Lituanie'
        elif 478 == int(pays_code):
            row['pays_origine'] = 'Ouzbékistan'
        elif pays_code == '479':
            row['pays_origine'] = 'Sri Lanka'
        elif pays_code == '480':
            row['pays_origine'] = 'Philippines'
        elif pays_code == '481':
            row['pays_origine'] = 'Biélorussie'
        elif pays_code == '482':
            row['pays_origine'] = 'Ukraine'
        elif pays_code == '484':
            row['pays_origine'] = 'Moldavie'
        elif pays_code == '485':
            row['pays_origine'] = 'Arménie'
        elif pays_code == '486':
            row['pays_origine'] = 'Géorgie'
        elif pays_code == '487':
            row['pays_origine'] = 'Kazakhstan'
        elif pays_code == '489':
            row['pays_origine'] = 'Hong Kong'
        elif pays_code in ('490', '491', '492', '493', '494', '495', '496', '497', '498', '499'):
            row['pays_origine'] = 'Japon'
        elif pays_code == '500':
            row['pays_origine'] = 'Royaume-Uni'
        elif pays_code == '520':
            row['pays_origine'] = 'Grèce'
        elif pays_code == '528':
            row['pays_origine'] = 'Liban'
        elif pays_code == '529':
            row['pays_origine'] = 'Chypre'
        elif pays_code == '530':
            row['pays_origine'] = 'Albanie'
        elif pays_code == '531':
            row['pays_origine'] = 'Macédoine'
        elif pays_code == '535':
            row['pays_origine'] = 'Malte'
        elif pays_code == '539':
            row['pays_origine'] = 'Irlande'
        elif pays_code in ('540', '541', '542', '543', '544', '545', '546', '547', '548', '549'):
            row['pays_origine'] = 'Belgique & Luxembourg'
        elif pays_code == '560':
            row['pays_origine'] = 'Portugal'
        elif pays_code == '569':
            row['pays_origine'] = 'Islande'
        elif pays_code in ('570', '571', '572', '573', '574', '575', '576', '577', '578', '579'):
            row['pays_origine'] = 'Danemark'
        elif pays_code == '590':
            row['pays_origine'] = 'Pologne'
        elif pays_code == '594':
            row['pays_origine'] = 'Roumanie'
        elif pays_code == '599':
            row['pays_origine'] = 'Hongrie'
        elif pays_code in ('600', '601'):
            row['pays_origine'] = 'Afrique du Sud'
        elif pays_code == '603':
            row['pays_origine'] = 'Ghana'
        elif pays_code == '608':
            row['pays_origine'] = 'Bahreïn'
        elif pays_code == '609':
            row['pays_origine'] = 'Île Maurice'
        elif pays_code == '611':
            row['pays_origine'] = 'Maroc'
        elif pays_code == '613':
            row['pays_origine'] = 'Algérie'
        elif pays_code == '616':
            row['pays_origine'] = 'Kenya'
        elif pays_code == '618':
            row['pays_origine'] = "Côte d'Ivoire"
        elif pays_code == '619':
            row['pays_origine'] = 'Tunisie'
        elif pays_code == '621':
            row['pays_origine'] = 'Syrie'
        elif pays_code == '622':
            row['pays_origine'] = 'Égypte'
        elif pays_code == '624':
            row['pays_origine'] = 'Libye'
        elif pays_code == '625':
            row['pays_origine'] = 'Jordanie'
        elif pays_code == '626':
            row['pays_origine'] = 'Iran'
        elif pays_code == '627':
            row['pays_origine'] = 'Koweït'
        elif pays_code == '628':
            row['pays_origine'] = 'Arabie Saoudite'
        elif pays_code == '629':
            row['pays_origine'] = 'Émirats Arabes Unis'
        elif pays_code in ('640', '641', '642', '643', '644', '645', '646', '647', '648', '649'):
            row['pays_origine'] = 'Finlande'
        elif pays_code in ('690', '691', '692', '693', '694', '695'):
            row['pays_origine'] = 'Chine'
        elif pays_code in ('700', '701', '702', '703', '704', '705', '706', '707', '708', '709'):
            row['pays_origine'] = 'Norvège'
        elif pays_code == '729':
            row['pays_origine'] = 'Israël'
        elif pays_code in ('730', '731', '732', '733', '734', '735', '736', '737', '738', '739'):
            row['pays_origine'] = 'Suède'
        elif pays_code == '740':
            row['pays_origine'] = 'Guatemala'
        elif pays_code == '741':
            row['pays_origine'] = 'Salvador'
        elif pays_code == '742':
            row['pays_origine'] = 'Honduras'
        elif pays_code == '743':
            row['pays_origine'] = 'Nicaragua'
        elif pays_code == '744':
            row['pays_origine'] = 'Costa Rica'
        elif pays_code == '745':
            row['pays_origine'] = 'Panama'
        elif pays_code == '746':
            row['pays_origine'] = 'République Dominicaine'
        elif pays_code == '750':
            row['pays_origine'] = 'Mexique'
        elif pays_code in ('754', '755'):
            row['pays_origine'] = 'Canada'
        elif pays_code == '759':
            row['pays_origine'] = 'Venezuela'
        elif pays_code in ('760', '761', '762', '763', '764', '765', '766', '767', '768', '769'):
            row['pays_origine'] = 'Suisse'
        elif pays_code in ('770', '771', '772', '773', '774', '775'):
            row['pays_origine'] = 'Colombie'
        elif pays_code == '779':
            row['pays_origine'] = 'Argentine'
        elif pays_code == '780':
            row['pays_origine'] = 'Chili'
        elif pays_code == '784':
            row['pays_origine'] = 'Paraguay'
        elif pays_code == '786':
            row['pays_origine'] = 'Équateur'
        elif pays_code in ('789', '790'):
            row['pays_origine'] = 'Brésil'
        elif pays_code in ('800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819'):
            row['pays_origine'] = 'Italie'
        elif pays_code in ('840', '841', '842', '843', '844', '845', '846', '847', '848', '849'):
            row['pays_origine'] = 'Espagne'
        elif pays_code == '850':
            row['pays_origine'] = 'Cuba'
        elif pays_code == '858':
            row['pays_origine'] = 'Slovaquie'
        elif pays_code == '859':
            row['pays_origine'] = 'République tchèque'
        elif pays_code == '860':
            row['pays_origine'] = 'Serbie Monténégro'
        elif pays_code == '865':
            row['pays_origine'] = 'Mongolie'
        elif pays_code == '867':
            row['pays_origine'] = 'Corée du Nord'
        elif pays_code == '869':
            row['pays_origine'] = 'Turquie'
        elif pays_code in ('870', '871', '872', '873', '874', '875', '876', '877', '878', '879'):
            row['pays_origine'] = 'Pays-Bas'
        elif pays_code == '880':
            row['pays_origine'] = 'Corée du Sud'
        elif pays_code == '884':
            row['pays_origine'] = 'Cambodge'
        elif pays_code == '885':
            row['pays_origine'] = 'Thaïlande'
        elif pays_code == '888':
            row['pays_origine'] = 'Singapour'
        elif pays_code == '890':
            row['pays_origine'] = 'Inde'
        elif pays_code == '893':
            row['pays_origine'] = 'Vietnam'
        elif pays_code == '899':
            row['pays_origine'] = 'Indonésie'
        elif pays_code in ('900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919'):
            row['pays_origine'] = 'Autriche'
        elif pays_code in ('930', '931', '932', '933', '934', '935', '936', '937', '938', '939'):
            row['pays_origine'] = 'Australie'
        elif pays_code in ('940', '941', '942', '943', '944', '945', '946', '947', '948', '949'):
            row['pays_origine'] = 'Nouvelle-Zélande'
        elif pays_code == '955':
            row['pays_origine'] = 'Malaisie'
        elif pays_code == '958':
            row['pays_origine'] = 'Macao'

    # Si le code-barres n'est pas indiqué, définir sur "No info"
    else:
        row['pays_origine'] = 'No info'

    return row

df_pays_origine = df_pays_origine.apply(extract_info, axis=1)

df_pays_origine.head(5)

data_conso_final = df_pays_origine.copy()

data_conso_final.to_excel('output.xlsx', index=False)